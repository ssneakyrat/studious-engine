# Default configuration for Singing Voice Synthesis (SVS) model

# Data preprocessing parameters
preprocessing:
  sample_rate: 22050  # Audio sample rate for vocal quality
  n_fft: 1024         # FFT window size balances frequency and time resolution
  hop_length: 256     # 12.5ms frames at 22050Hz for smooth transitions
  n_mels: 80          # Number of mel bins - standard for voice synthesis
  f0_min: 80          # Minimum F0 in Hz (low vocal range)
  f0_max: 800         # Maximum F0 in Hz (high vocal range)
  # Higher sample rate captures high-frequency details in singing
  # Smaller hop_length produces smoother mel spectrograms but increases sequence length

# Dataset parameters
dataset:
  train_split: 0.9    # 90% training data provides sufficient examples
  eval_split: 0.1     # 10% validation data for model evaluation
  batch_size: 16      # Balances memory usage and training stability
  num_workers: 4      # Parallel data loading for GPU utilization
  pin_memory: true    # Faster data transfer to GPU
  # Larger batch sizes help training stability but use more VRAM
  # Multiple workers improve loading speed with diminishing returns beyond CPU core count
  datasets_dir: datasets/gin

# Model architecture
model:
  # Embedding dimensions
  phoneme_dim: 128    # Rich representation for phoneme context
  pitch_dim: 64       # Smaller dimension sufficient for pitch information
  
  # Encoder
  encoder_dim: 256    # GRU hidden states size for capturing temporal patterns
  encoder_layers: 2   # Sufficient depth for linguistic feature extraction
  
  # VAE
  latent_dim: 64      # Compact latent space for voice characteristics
  
  # Decoder
  decoder_dim: 256    # Matches encoder for balanced expressiveness
  decoder_layers: 2   # Balanced depth for reconstruction quality
  
  # Post-processing
  postnet_channels: 512  # Wide channels for spectral refinement
  postnet_layers: 5      # Multiple layers for detailed corrections
  postnet_kernel: 5      # Captures local spectral relationships
  
  # Higher latent_dim enables more expressiveness but may reduce controllability
  # Deeper GRU layers capture more temporal patterns but require more data
  # Postnet significantly improves output quality by reducing artifacts

# Training parameters
training:
  lr: 0.001           # Standard learning rate for Adam optimizer
  weight_decay: 1e-6  # Light regularization to prevent overfitting
  epochs: 100         # Upper limit for convergence with early stopping
  kl_weight_init: 0.0 # Start with no KL penalty for stable initialization
  kl_weight_end: 0.01 # Low final weight preserves reconstruction quality
  kl_annealing_epochs: 20  # Gradual introduction of KL constraint
  grad_clip: 1.0      # Prevents gradient explosions
  early_stop_patience: 10  # Stops training when improvements plateau
  mel_loss_weight: 1.0     # Prioritizes spectrogram reconstruction
  # KL annealing is critical for stable VAE training
  # Low KL weight prioritizes reconstruction over regularization
  # Gradient clipping essential for RNN training stability

# Logging
logging:
  log_interval: 100   # Updates progress bar every 100 steps
  eval_interval: 1    # Evaluates model every epoch
  sample_interval: 5  # Generates examples every 5 epochs
  # Frequent evaluation monitors overfitting
  # Visual samples help assess voice quality beyond metrics